# Orchestrator Configuration
PORT=3000
REDIS_URL=redis://localhost:6379

# LLM Selection: gemini | claude | openai
LLM_PROVIDER=gemini

# Provider Keys (Only the one for the selected provider is strictly required)
GEMINI_API_KEY=
ANTHROPIC_API_KEY=
OPENAI_API_KEY=

# LLM Response Configuration
# Maximum output tokens for LLM responses (default: 8192)
# Increase for longer responses, decrease to reduce API costs
MAX_OUTPUT_TOKENS=8192

# Phase 2 Optimizations: Container Pooling
# Enable container pooling for 5-10x capacity improvement
# Reduces container acquisition time from 2-5s to <100ms
ENABLE_CONTAINER_POOL=false
POOL_MIN_SIZE=10
POOL_MAX_SIZE=100
POOL_IDLE_TIMEOUT_MS=900000

# Phase 3 Optimizations: Advanced Features
# Worker architecture for stateless orchestrator
ENABLE_WORKER_MODE=false
WORKER_CONCURRENCY=10

# Memory optimizations
ENABLE_CONVERSATION_COMPRESSION=false
STREAM_OUTPUT_THRESHOLD_BYTES=1048576

# Job queue settings
JOB_TIMEOUT_MS=300000

# Conversation History Management
# Token-based history limits to prevent LLM context overflow
MAX_HISTORY_TOKENS=50000          # Max tokens in history (default: 50k)
HISTORY_TTL_SECONDS=86400         # Redis TTL for history keys (default: 24h)
# Note: ENABLE_CONVERSATION_COMPRESSION above should be enabled for optimal memory usage
